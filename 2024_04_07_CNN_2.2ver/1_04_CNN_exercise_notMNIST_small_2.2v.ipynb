{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxdOtFwGD0S6"
   },
   "source": [
    "# Keras Upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4xxbLUhD0G9"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_iAjwPm_mYg"
   },
   "source": [
    "# Letter recognition (small size)\n",
    "\n",
    "> Indeed, I once even proposed that the toughest challenge facing AI workers is to answer the question: “What are the letters ‘A’ and ‘I’? - [Douglas R. Hofstadter](https://web.stanford.edu/group/SHR/4-2/text/hofstadter.html) (1995)\n",
    "\n",
    "\n",
    "## notMNIST\n",
    "\n",
    "\n",
    "Data source: [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) (you need to download `notMNIST_small.mat` file):\n",
    "\n",
    "![](http://yaroslavvb.com/upload/notMNIST/nmn.png)\n",
    "\n",
    "> some publicly available fonts and extracted glyphs from them to make a dataset similar to MNIST. There are 10 classes, with letters A-J taken from different fonts.\n",
    "\n",
    "> Approaching 0.5% error rate on notMNIST_small would be very impressive. If you run your algorithm on this dataset, please let me know your results.\n",
    "\n",
    "\n",
    "## So, why not MNIST?\n",
    "\n",
    "Many introductions to image classification with deep learning start with MNIST, a standard dataset of handwritten digits. This is unfortunate. Not only does it not produce a “Wow!” effect or show where deep learning shines, but it also can be solved with shallow machine learning techniques. In this case, plain k-Nearest Neighbors produces more than 97% accuracy (or even 99.5% with some data preprocessing!). Moreover, MNIST is not a typical image dataset – and mastering it is unlikely to teach you transferable skills that would be useful for other classification problems\n",
    "\n",
    "> Many good ideas will not work well on MNIST (e.g. batch norm). Inversely many bad ideas may work on MNIST and no[t] transfer to real [computer vision]. - [François Chollet’s tweet](https://twitter.com/fchollet/status/852594987527045120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcAAphar__K6"
   },
   "outputs": [],
   "source": [
    "!wget http://yaroslavvb.com/upload/notMNIST/notMNIST_small.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bJ8z5dnANsf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsvxhuP0_mYt"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGjiGlIJmt5Q"
   },
   "outputs": [],
   "source": [
    "data = io.loadmat('notMNIST_small.mat')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeNorDxNm0kJ"
   },
   "outputs": [],
   "source": [
    "x = data['images']\n",
    "y = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ync3Gzrim3VI"
   },
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYB_hI-7m58Y"
   },
   "outputs": [],
   "source": [
    "resolution = 28\n",
    "classes = 10\n",
    "\n",
    "x = np.transpose(x, (2, 0, 1))\n",
    "print(x.shape)\n",
    "x = x.reshape( (-1, resolution, resolution, 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPlIBhtrnUbZ"
   },
   "outputs": [],
   "source": [
    "# sample, x, y, channel\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGxezpUTnv4G"
   },
   "source": [
    "* 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrHUkjstndza"
   },
   "outputs": [],
   "source": [
    "rand_i = np.random.randint(0, x.shape[0])\n",
    "\n",
    "plt.title( f'idx: {rand_i} , y: {\"ABCDEFGHIJ\"[ int(y[rand_i]) ]}' )\n",
    "plt.imshow( x[rand_i, :, :, 0], cmap='gray' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7vYrb85CsSKV"
   },
   "outputs": [],
   "source": [
    "rows = 5\n",
    "fig, axes = plt.subplots(rows, classes, figsize=(classes,rows))\n",
    "\n",
    "for letter_id in range(classes) :\n",
    "    letters = x[y==letter_id]      # 0부터 9까지 각 숫자에 맞는 array가 letters에 들어간다.\n",
    "    letters_len = len(letters)\n",
    "\n",
    "    for row_i in range(rows) :\n",
    "        axe = axes[row_i, letter_id]\n",
    "        axe.imshow( letters[np.random.randint(letters_len)], cmap='gray', interpolation='none')\n",
    "        axe.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KG6mnMZkw3iz"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leN2EkZUv8um"
   },
   "source": [
    "* Data split\n",
    "\n",
    "    - training set : test set = 8 : 2\n",
    "    - 재현을 위한 난수 고정 : 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RltGdpJVHqHm"
   },
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tt2773nnAmVX"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUrGknkXHCnB"
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0BZmBNBFHt3f"
   },
   "outputs": [],
   "source": [
    "train_x.shape , train_y.shape , test_x.shape , test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6wdqmy9xglU"
   },
   "source": [
    "* Scaling\n",
    "\n",
    "    - min-max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_H5ZJQ2xgiB"
   },
   "outputs": [],
   "source": [
    "max_n, min_n = train_x.max(), train_x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0HOD2R_xz20"
   },
   "outputs": [],
   "source": [
    "train_x = (train_x - min_n) / (max_n - min_n)\n",
    "test_x = (test_x - min_n) / (max_n - min_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ciZP9h4x8F1"
   },
   "outputs": [],
   "source": [
    "train_x.max(), train_x.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7VEtyVIxgeW"
   },
   "source": [
    "* One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxL4r3qhxDdx"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQ7VK412yWPv"
   },
   "outputs": [],
   "source": [
    "class_len = len(np.unique(train_y))\n",
    "class_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIRcIJxRyDHM"
   },
   "outputs": [],
   "source": [
    "train_y = to_categorical(train_y, class_len)\n",
    "test_y = to_categorical(test_y, class_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X072_BHJzpcF"
   },
   "source": [
    "* Data shape 재확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h41qEPDYAoxj"
   },
   "outputs": [],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnZHnb1uBJWj"
   },
   "source": [
    "## Modeling : CNN\n",
    "\n",
    "- 조건\n",
    "    1. Sequential API, Functiona API 중 택일.\n",
    "    2. [이 구조를 미니 버전으로 활용해봐도 좋다.](https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99DFA5415B38AC752E)\n",
    "    3. DropOut, BatchNormalization 등의 기능도 같이 활용해보자.\n",
    "    4. Early Stopping을 사용할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezIuD3U-IA5G"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.backend import clear_session\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout\n",
    "from keras.layers import Conv2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVgV9a10H8hv"
   },
   "source": [
    "* Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ljvPeDC2UHu"
   },
   "outputs": [],
   "source": [
    "# 1. 세션 클리어\n",
    "clear_session()\n",
    "\n",
    "# 2. 모델 선언\n",
    "model1 = Sequential()\n",
    "\n",
    "# 3. 레이어 블록 조립\n",
    "model1.add( Input(shape=(28,28,1)) )\n",
    "\n",
    "model1.add( Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n",
    "                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n",
    "                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n",
    "                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n",
    "                   activation='relu',   # 빼먹지 않게 주의!\n",
    "                   ) )\n",
    "model1.add( Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n",
    "                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n",
    "                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n",
    "                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n",
    "                   activation='relu',   # 빼먹지 않게 주의!\n",
    "                   ) )\n",
    "model1.add( MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n",
    "                      strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n",
    "                      ) )\n",
    "model1.add( BatchNormalization() )\n",
    "model1.add( Dropout(0.2) )\n",
    "\n",
    "model1.add( Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n",
    "                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n",
    "                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n",
    "                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n",
    "                   activation='relu',   # 빼먹지 않게 주의!\n",
    "                   ) )\n",
    "model1.add( Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n",
    "                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n",
    "                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n",
    "                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n",
    "                   activation='relu',   # 빼먹지 않게 주의!\n",
    "                   ) )\n",
    "model1.add( MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n",
    "                      strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n",
    "                      ) )\n",
    "model1.add( BatchNormalization() )\n",
    "model1.add( Dropout(0.2) )\n",
    "\n",
    "model1.add( Flatten() )\n",
    "model1.add( Dense(256, activation='relu') )\n",
    "model1.add( Dense(10, activation='softmax') )\n",
    "\n",
    "# 4. 컴파일\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAVRrRPcKKcp"
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZZjZT7TKRLA"
   },
   "outputs": [],
   "source": [
    "plot_model(model1, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZtJnfRIH-Ar"
   },
   "source": [
    "* Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VS-qEdDwH-Op"
   },
   "outputs": [],
   "source": [
    "# 1. 세션 클리어\n",
    "clear_session()\n",
    "\n",
    "# 2. 레이어 엮기\n",
    "il = Input(shape=(28,28,1))\n",
    "\n",
    "hl = Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n",
    "            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n",
    "            strides=(1,1),       # Conv2D 필터의 이동 보폭\n",
    "            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n",
    "            activation='relu',   # 빼먹지 않게 주의!\n",
    "            )(il)\n",
    "hl = Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n",
    "            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n",
    "            strides=(1,1),       # Conv2D 필터의 이동 보폭\n",
    "            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n",
    "            activation='relu',   # 빼먹지 않게 주의!\n",
    "            )(hl)\n",
    "hl = MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n",
    "               strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n",
    "               )(hl)\n",
    "hl = BatchNormalization()(hl)\n",
    "hl = Dropout(0.2)(hl)\n",
    "\n",
    "hl = Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n",
    "            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n",
    "            strides=(1,1),       # Conv2D 필터의 이동 보폭\n",
    "            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n",
    "            activation='relu',   # 빼먹지 않게 주의!\n",
    "            )(hl)\n",
    "hl = Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n",
    "            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n",
    "            strides=(1,1),       # Conv2D 필터의 이동 보폭\n",
    "            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n",
    "            activation='relu',   # 빼먹지 않게 주의!\n",
    "            )(hl)\n",
    "hl = MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n",
    "               strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n",
    "               )(hl)\n",
    "hl = BatchNormalization()(hl)\n",
    "hl = Dropout(0.2)(hl)\n",
    "\n",
    "hl = Flatten()(hl)\n",
    "hl = Dense(256, activation='relu')(hl)\n",
    "ol = Dense(10, activation='softmax')(hl)\n",
    "\n",
    "# 3. 모델의 시작과 끝 지정\n",
    "model2 = Model(il, ol)\n",
    "\n",
    "# 4. 컴파일\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcTn6To3LutJ"
   },
   "outputs": [],
   "source": [
    "plot_model(model2, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hpnt-37bF_F6"
   },
   "source": [
    "* Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PU9dUzJX2V-g"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olJWlT5-L0yX"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss',          # 얼리 스토핑을 적용할 관측 대상\n",
    "                   min_delta=0,                 # Threshold. 설정한 값 이상으로 변해야 성능 개선되었다고 간주.\n",
    "                   patience=3,                  # 성능 개선이 발생하지 않았을 때, 몇 epoch를 더 지켜볼 것인가.\n",
    "                   verbose=1,\n",
    "                   restore_best_weights=True)   # 성능이 가장 좋은 epoch의 가중치를 적용함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKhZAhT6GCYA"
   },
   "source": [
    "* .fit( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vau9RsfDGCGN"
   },
   "outputs": [],
   "source": [
    "model1.fit(train_x, train_y, epochs=20, verbose=1,\n",
    "           validation_split=0.2,  # 매 epoch마다 training set의 20%를 validation set으로 만듬\n",
    "           callbacks=[es]         # 얼리스토핑 적용\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OADy5fyHGEMd"
   },
   "source": [
    "* .evaluate( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpZMsGCtGEbh"
   },
   "outputs": [],
   "source": [
    "model1.evaluate(test_x, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG1lgszsn6LT"
   },
   "source": [
    "* .predict( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gadVLHGFEF2i"
   },
   "outputs": [],
   "source": [
    "y_pred = model1.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8EDi6-HZGV7T"
   },
   "outputs": [],
   "source": [
    "# 원핫 인코딩 한 것을 다시 묶어주는 코드\n",
    "# 평가 지표 및 실제 데이터 확인을 위해 필요\n",
    "\n",
    "y_pred_arg = np.argmax(y_pred, axis=1)\n",
    "test_y_arg = np.argmax(test_y, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0i7gtoKQI2M"
   },
   "source": [
    "* 평가 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0bKlDKAJO6Q"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKaSctmxJSR_"
   },
   "outputs": [],
   "source": [
    "accuracy_score(test_y_arg, y_pred_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFCAI30pInVp"
   },
   "outputs": [],
   "source": [
    "class_names = ['A','B','C','D','E','F','G','H','I','J']\n",
    "\n",
    "print( classification_report(test_y_arg, y_pred_arg, target_names=class_names) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dX0PzsnZGdIh"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAz06dlD7Gno"
   },
   "source": [
    "* 실제 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDzw-qDE7Eoc"
   },
   "outputs": [],
   "source": [
    "letters_str = \"ABCDEFGHIJ\"\n",
    "\n",
    "rand_idx = np.random.randint(0, len(y_pred_arg))\n",
    "test_idx = test_y_arg[rand_idx]\n",
    "pred_idx = y_pred_arg[rand_idx]\n",
    "class_prob = np.floor( y_pred[rand_idx]*100 )\n",
    "\n",
    "print(f'idx = {rand_idx}')\n",
    "print(f'해당 인덱스의 이미지는 {letters_str[test_idx]}')\n",
    "print(f'모델의 예측 : {letters_str[pred_idx]}')\n",
    "print(f'모델의 클래스별 확률 : ')\n",
    "print('-------------------')\n",
    "for idx, val in enumerate(letters_str) :\n",
    "    print(val, class_prob[idx])\n",
    "print('=================================================')\n",
    "\n",
    "if test_y_arg[rand_idx] == y_pred_arg[rand_idx] :\n",
    "    print('정답')\n",
    "else :\n",
    "    print('땡')\n",
    "\n",
    "plt.imshow(test_x[rand_idx], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7lHIf-B9Z_L"
   },
   "source": [
    "* 틀린 이미지만 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnLoTiF0LZEU"
   },
   "outputs": [],
   "source": [
    "temp = (test_y_arg == y_pred_arg)\n",
    "false_idx = np.where(temp==False)[0]\n",
    "false_len = len(false_idx)\n",
    "false_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWcCLIW2_ACh"
   },
   "outputs": [],
   "source": [
    "letters_str = \"ABCDEFGHIJ\"\n",
    "\n",
    "rand_idx = false_idx[np.random.randint(0, false_len)]\n",
    "test_idx = test_y_arg[rand_idx]\n",
    "pred_idx = y_pred_arg[rand_idx]\n",
    "class_prob = np.floor( y_pred[rand_idx]*100 )\n",
    "\n",
    "print(f'idx = {rand_idx}')\n",
    "print(f'해당 인덱스의 이미지는 {letters_str[test_idx]}')\n",
    "print(f'모델의 예측 : {letters_str[pred_idx]}')\n",
    "print(f'모델의 클래스별 확률 : ')\n",
    "print('-------------------')\n",
    "for idx, val in enumerate(letters_str) :\n",
    "    print(val, class_prob[idx])\n",
    "print('=================================================')\n",
    "\n",
    "if test_y_arg[rand_idx] == y_pred_arg[rand_idx] :\n",
    "    print('정답')\n",
    "else :\n",
    "    print('땡')\n",
    "\n",
    "plt.imshow(test_x[rand_idx], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvZmaNwWOAgd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
