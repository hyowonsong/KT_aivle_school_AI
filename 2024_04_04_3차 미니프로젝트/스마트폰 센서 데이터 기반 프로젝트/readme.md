# ğŸ“± **ìŠ¤ë§ˆíŠ¸í° ì„¼ì„œ ë°ì´í„° ê¸°ë°˜ ëª¨ì…˜ ë¶„ë¥˜ í”„ë¡œì íŠ¸(3ì°¨ ë¯¸ë‹ˆ í”„ë¡œì íŠ¸)**

---

## **ğŸ“Š í”„ë¡œì íŠ¸ ê°œìš”**

- **ëª©ì :** ìŠ¤ë§ˆíŠ¸í° ì„¼ì„œ ë°ì´í„°ë¥¼ í™œìš©í•´ ì‚¬ìš©ìì˜ ëª¨ì…˜ì„ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ êµ¬ì¶•
- **ê¸°ê°„:** 2024.04.04 ~ 2024.04.08
- **ë°ì´í„°:** [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones)
- **ì‚¬ìš© ë„êµ¬:** Python, Pandas, Matplotlib, Seaborn, Scikit-learn

---

## ğŸ“‘ **í”„ë¡œì íŠ¸ ë‹¨ê³„**

### **ë‹¨ê³„ 1**: ì •ì (0), ë™ì (1) í–‰ë™ ë¶„ë¥˜ ëª¨ë¸ ìƒì„±

- **ëª©í‘œ**: ì‚¬ìš©ìì˜ í–‰ë™ì„ ì •ì ê³¼ ë™ì ìœ¼ë¡œ ë¶„ë¥˜
- **ëª¨ë¸ë§ ë°©ë²•**: ì—¬ëŸ¬ ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•´ ëª¨ë¸ë§ì„ ìˆ˜í–‰í•˜ê³ , ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ì„ ì„ ì •

### **ë‹¨ê³„ 2**: ì„¸ë¶€ ë™ì‘ ë¶„ë¥˜ ëª¨ë¸ ìƒì„±

- **ëª©í‘œ**: ë‹¨ê³„ 1ì—ì„œ ì˜ˆì¸¡í•œ í–‰ë™ì„ ê¸°ì¤€ìœ¼ë¡œ, ì„¸ë¶€ ë™ì‘ì„ ì¶”ê°€ì ìœ¼ë¡œ ë¶„ë¥˜
    - **ì •ì  í–‰ë™ ë¶„ë¥˜**: Laying, Sitting, Standing
    - **ë™ì  í–‰ë™ ë¶„ë¥˜**: Walking, Walking Upstairs, Walking Downstairs
- **ëª¨ë¸ë§ ë°©ë²•**: ì—¬ëŸ¬ ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•´ ê° ë™ì‘ì„ ë¶„ë¥˜í•˜ê³ , ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ì„ ì„ ì •

### **ëª¨ë¸ í†µí•©**

- **ëª©í‘œ**: ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆˆ ëª¨ë¸ì„ í†µí•©í•´ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë„ì¶œ
- **ì„±ëŠ¥ í‰ê°€**: í†µí•©ëœ ëª¨ë¸ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ , ìµœì ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±

---

## ğŸ› ï¸ **í™˜ê²½ ì„¤ì •**

### 1ï¸âƒ£ **í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import warnings
import re
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.metrics import *
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score
from sklearn.preprocessing import MinMaxScaler, StandardScaler
```

### 2ï¸âƒ£ **ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°**

```python
data = pd.read_csv('data01_train.csv')
new_data = pd.read_csv('data01_test.csv')
data = data.drop('subject', axis = 1)
data.head()
```

---

## ğŸ§¹ **ë°ì´í„° ì „ì²˜ë¦¬**

### 1ï¸âƒ£ **Label ì¶”ê°€ ë° ë°ì´í„° ë¶„í• **

- **Activity_dynamic**: ì •ì (0) ë˜ëŠ” ë™ì (1) ì—¬ë¶€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë¼ë²¨ì„ ì¶”ê°€
- **Train/Validation Split**: `train`ê³¼ `val` ë°ì´í„°ë¥¼ 8:2 ë¡œ ë¶„í• 

```python
data['Activity_dynamic'] = np.where(data['Activity'].isin(['STANDING', 'SITTING', 'LAYING']), 0, 1)
X = data.drop(['Activity', 'Activity_dynamic'], axis = 1)
y1 = data['Activity']
y2 = data['Activity_dynamic']
X_train, X_val, y_train, y_val = train_test_split(X, y1, test_size = 0.2, random_state = 42)
X_train2, X_val2, y_train2, y_val2 = train_test_split(X, y2, test_size = 0.2, random_state = 42)
```

---

## ğŸ“Š **ë‹¨ê³„ë³„ ëª¨ë¸ë§**

### **ğŸ” ë‹¨ê³„ 1: ì •ì /ë™ì  í–‰ë™ ë¶„ë¥˜ ëª¨ë¸**

- **ì•Œê³ ë¦¬ì¦˜**: Random Forest
- **ëª¨ë¸ë§ ê²°ê³¼**: ë†’ì€ ì •í™•ë„ë¥¼ ê°€ì§„ Random Forest ëª¨ë¸ì„ ì„ ì •

```python
model_rf = RandomForestClassifier(random_state = 42)
model_rf.fit(X_train2, y_train2)
p_rf = model_rf.predict(X_val2)
```

- **ëª¨ë¸ ì„±ëŠ¥ í‰ê°€**
    - **Accuracy**: 98%
    - **Confusion Matrix** ë° **Classification Report** ì¶œë ¥.
    

### **ğŸ” ë‹¨ê³„ 2-1: ì •ì  ë™ì‘ ì„¸ë¶€ ë¶„ë¥˜**

- **ì•Œê³ ë¦¬ì¦˜**: CatBoost
- **íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„**: ìƒìœ„ 25ê°œ ì¤‘ìš”í•œ íŠ¹ì„±ì„ ì„ ì •í•˜ì—¬ ìµœì  ëª¨ë¸ êµ¬ì¶•.

```python
model_cat = CatBoostClassifier(random_state = 42, task_type = 'GPU', verbose = 0)
model_cat.fit(X_train_25, y_train3)
p_cat = model_cat.predict(X_val_25)
```

- **ëª¨ë¸ ì„±ëŠ¥ í‰ê°€**
    - **Accuracy**: 99%
    - **Confusion Matrix** ë° **Classification Report** ì¶œë ¥.

### **ğŸ” ë‹¨ê³„ 2-2: ë™ì  ë™ì‘ ì„¸ë¶€ ë¶„ë¥˜**

- **ì•Œê³ ë¦¬ì¦˜**: CatBoost
- **ëª¨ë¸ë§ ê²°ê³¼**: CatBoostë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì  ë™ì‘ ì„¸ë¶€ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰

```python
model_cat = CatBoostClassifier(random_state = 42, task_type = 'GPU', verbose = 0)
model_cat.fit(X_train4, y_train4)
p_cat = model_cat.predict(X_val4)
```

- **ëª¨ë¸ ì„±ëŠ¥ í‰ê°€**
    - **Accuracy**: 99%
    - **Confusion Matrix** ë° **Classification Report** ì¶œë ¥.

---

## ğŸ§  **ëª¨ë¸ í†µí•© ë° ì„±ëŠ¥ í‰ê°€**

### **í•¨ìˆ˜ êµ¬í˜„ ë° ëª¨ë¸ í†µí•©**

- **í•¨ìˆ˜**: ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³ , ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” í•¨ìˆ˜ ì‘ì„±.

```python
def predict_new_data(path):
    # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    new_data = pd.read_csv(path)
    new_data.drop('subject', axis=1, inplace=True)
    X_test = new_data.drop('Activity', axis = 1)
    y_test = new_data['Activity']

    # ëª¨ë¸ ë¡œë“œ
    model1 = joblib.load('model1.pkl')
    model2_1 = joblib.load('model2_1.pkl')
    model2_1_25 = joblib.load('model2_1_25.pkl')
    model2_2 = joblib.load('model2_2.pkl')
    top_25_feature = joblib.load('cat_top_25_features.pkl')

    # ë™ì  ì •ì  ìœ ë¬´ ì˜ˆì¸¡ ë° ì„¸ë¶€ ì˜ˆì¸¡
    pred1= model1.predict(X_test)
    # ì˜ˆì¸¡ ê²°ê³¼ í•©ì¹˜ê¸° ë° ì„±ëŠ¥ í‰ê°€
    print('<model2_1 all features>\\n')
    # í‰ê°€ ê²°ê³¼ ì¶œë ¥
```

- **ì„±ëŠ¥ í‰ê°€ ê²°ê³¼**
    - **All Features**: Accuracy 99%
    - **Top 25 Features**: Accuracy 99%

---

## ğŸ” **ê²°ë¡ **

- ë‹¨ê³„ë³„ ëª¨ë¸ë§ì„ í†µí•´ ë†’ì€ ì„±ëŠ¥ì˜ ì˜ˆì¸¡ ëª¨ë¸ì„ êµ¬ì¶•
- ì „ì²´ ì‹œìŠ¤í…œì„ í†µí•©í•˜ì—¬ ì¼ê´€ëœ ì„±ëŠ¥ì„ ìœ ì§€
- ê²°ê³¼ì ìœ¼ë¡œ,  **ë‹¤ì–‘í•œ ìŠ¤ë§ˆíŠ¸í° ì„¼ì„œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ í™œë™ì„ íš¨ê³¼ì ìœ¼ë¡œ ë¶„ë¥˜**
